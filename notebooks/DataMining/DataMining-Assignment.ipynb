{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data mining assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import collections\n",
    "import random\n",
    "# Visualization\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnknownClassifier(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__('Unknown classifier name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(N, ratio):\n",
    "    indexes = [i for i in range(N)]\n",
    "    limit = int(N * ratio)\n",
    "    # 3N scambi casuali\n",
    "    for i in range(3*N):\n",
    "        a = random.randrange(N)\n",
    "        b = random.randrange(N)\n",
    "        indexes[a], indexes[b] = indexes[b], indexes[a]\n",
    "    return indexes[limit:], indexes[:limit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers creation\n",
    "\n",
    "The classifiers that we will consider are:\n",
    "- Decision Tree ([link](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html))\n",
    "- SVC ([link](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "- Gaussian process classifier ([link](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html))\n",
    "- MLP ([link](earn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html))\n",
    "\n",
    "Which have been taken from this [list](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dt(parameters):\n",
    "    criterion = 'gini'\n",
    "    if 'criterion' in parameters:\n",
    "        criterion = parameters['criterion']\n",
    "    splitter = 'best'\n",
    "    if 'splitter' in parameters:\n",
    "        splitter = parameters['splitter']\n",
    "    max_depth = None\n",
    "    if 'max_depth' in parameters:\n",
    "            max_depth = parameters['max_depth']\n",
    "    min_samples_split = 2\n",
    "    if 'min_samples_split' in parameters:\n",
    "            min_samples_split = parameters['min_samples_split']\n",
    "    min_samples_leaf = 1\n",
    "    if 'min_samples_leaf' in parameters:\n",
    "            min_samples_leaf = parameters['min_samples_leaf']\n",
    "    min_weight_fraction_leaf = 0.0\n",
    "    if 'min_weight_fraction_leaf' in parameters:\n",
    "            min_weight_fraction_leaf = parameters['min_weight_fraction_leaf']\n",
    "    max_features = None\n",
    "    if 'max_features' in parameters:\n",
    "            max_features = parameters['max_features']\n",
    "    random_state = None\n",
    "    if 'random_state' in parameters:\n",
    "            random_state = parameters['random_state']\n",
    "    max_leaf_nodes = None\n",
    "    if 'max_leaf_nodes' in parameters:\n",
    "            max_leaf_nodes = parameters['max_leaf_nodes']\n",
    "    min_impurity_decrease = 0.0\n",
    "    if 'min_impurity_decrease' in parameters:\n",
    "            min_impurity_decrease = parameters['min_impurity_decrease']\n",
    "    class_weight = None\n",
    "    if 'class_weight' in parameters:\n",
    "            class_weight = parameters['class_weight']\n",
    "    ccp_alpha = 0.0\n",
    "    if 'ccp_alpha' in parameters:\n",
    "            ccp_alpha = parameters['ccp_alpha']\n",
    "\n",
    "    return DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        splitter=splitter,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=random_state,\n",
    "        max_leaf_nodes=max_leaf_nodes,\n",
    "        min_impurity_decrease=min_impurity_decrease,\n",
    "        class_weight=class_weight,\n",
    "        ccp_alpha=ccp_alpha,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_svc(parameters):\n",
    "    C = 1.0\n",
    "    if 'C' in parameters:\n",
    "        C = parameters['C']\n",
    "    kernel = 'rbf'\n",
    "    if 'kernel' in parameters:\n",
    "        kernel = parameters['kernel']\n",
    "    degree = 3\n",
    "    if 'degree' in parameters:\n",
    "        degree = parameters['degree']\n",
    "    gamma = 'scale'\n",
    "    if 'gamma' in parameters:\n",
    "        gamma = parameters['gamma']\n",
    "    coef0 = 0.0\n",
    "    if 'coef0' in parameters:\n",
    "        coef0 = parameters['coef0']\n",
    "    shrinking = True\n",
    "    if 'shrinking' in parameters:\n",
    "        shrinking = parameters['shrinking']\n",
    "    probability = False\n",
    "    if 'probability' in parameters:\n",
    "        probability = parameters['probability']\n",
    "    tol = 1e-3\n",
    "    if 'tol' in parameters:\n",
    "        tol = parameters['tol']\n",
    "    cache_size = 200\n",
    "    if 'cache_size' in parameters:\n",
    "        cache_size = parameters['cache_size']\n",
    "    class_weight = None\n",
    "    if 'class_weight' in parameters:\n",
    "        class_weight = parameters['class_weight']\n",
    "    verbose = False\n",
    "    if 'verbose' in parameters:\n",
    "        verbose = parameters['verbose']\n",
    "    max_iter = -1\n",
    "    if 'max_iter' in parameters:\n",
    "        max_iter = parameters['max_iter']\n",
    "    decision_function_shape = 'ovr'\n",
    "    if 'decision_function_shape' in parameters:\n",
    "        decision_function_shape = parameters['decision_function_shape']\n",
    "    break_ties = False\n",
    "    if 'break_ties' in parameters:\n",
    "        break_ties = parameters['break_ties']\n",
    "    random_state = None\n",
    "    if 'random_state' in parameters:\n",
    "        random_state = parameters['random_state']\n",
    "\n",
    "    return SVC(\n",
    "        C=C,\n",
    "        kernel=kernel,\n",
    "        degree=degree,\n",
    "        gamma=gamma,\n",
    "        coef0=coef0,\n",
    "        shrinking=shrinking,\n",
    "        probability=probability,\n",
    "        tol=tol, cache_size=cache_size,\n",
    "        class_weight=class_weight,\n",
    "        verbose=verbose,\n",
    "        max_iter=max_iter,\n",
    "        decision_function_shape=decision_function_shape,\n",
    "        break_ties=break_ties,\n",
    "        random_state=random_state\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gp(parameters):\n",
    "    kernel = None\n",
    "    if 'kernel' in parameters:\n",
    "            kernel = parameters['kernel']\n",
    "    optimizer = 'fmin_l_bfgs_b'\n",
    "    if 'optimizer' in parameters:\n",
    "            optimizer = parameters['optimizer']\n",
    "    n_restarts_optimizer = 0\n",
    "    if 'n_restarts_optimizer' in parameters:\n",
    "            n_restarts_optimizer = parameters['n_restarts_optimizer']\n",
    "    max_iter_predict = 100\n",
    "    if 'max_iter_predict' in parameters:\n",
    "            max_iter_predict = parameters['max_iter_predict']\n",
    "    warm_start = False\n",
    "    if 'warm_start' in parameters:\n",
    "            warm_start = parameters['warm_start']\n",
    "    copy_X_train = True\n",
    "    if 'copy_X_train' in parameters:\n",
    "            copy_X_train = parameters['copy_X_train']\n",
    "    random_state = None\n",
    "    if 'random_state' in parameters:\n",
    "            random_state = parameters['random_state']\n",
    "    multi_class = 'one_vs_rest'\n",
    "    if 'multi_class' in parameters:\n",
    "            multi_class = parameters['multi_class']\n",
    "    n_jobs = None\n",
    "    if 'n_jobs' in parameters:\n",
    "            n_jobs = parameters['n_jobs']\n",
    "\n",
    "    return GaussianProcessClassifier(\n",
    "        kernel=kernel,\n",
    "        optimizer=optimizer,\n",
    "        n_restarts_optimizer=n_restarts_optimizer,\n",
    "        max_iter_predict=max_iter_predict,\n",
    "        warm_start=warm_start,\n",
    "        copy_X_train=copy_X_train,\n",
    "        random_state=random_state,\n",
    "        multi_class=multi_class,\n",
    "        n_jobs=n_jobs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(parameters):\n",
    "    hidden_layer_sizes = (100,)\n",
    "    if 'hidden_layer_sizes' in parameters:\n",
    "            hidden_layer_sizes = parameters['hidden_layer_sizes']\n",
    "    activation = 'relu'\n",
    "    if 'activation' in parameters:\n",
    "            activation = parameters['activation']\n",
    "    solver = 'adam'\n",
    "    if 'solver' in parameters:\n",
    "            solver = parameters['solver']\n",
    "    alpha = 0.0001\n",
    "    if 'alpha' in parameters:\n",
    "            alpha = parameters['alpha']\n",
    "    batch_size = 'auto'\n",
    "    if 'batch_size' in parameters:\n",
    "            batch_size = parameters['batch_size']\n",
    "    learning_rate = 'constant'\n",
    "    if 'learning_rate' in parameters:\n",
    "            learning_rate = parameters['learning_rate']\n",
    "    learning_rate_init = 0.001\n",
    "    if 'learning_rate_init' in parameters:\n",
    "            learning_rate_init = parameters['learning_rate_init']\n",
    "    power_t = 0.5\n",
    "    if 'power_t' in parameters:\n",
    "            power_t = parameters['power_t']\n",
    "    max_iter = 200\n",
    "    if 'max_iter' in parameters:\n",
    "            max_iter = parameters['max_iter']\n",
    "    shuffle = True\n",
    "    if 'shuffle' in parameters:\n",
    "            shuffle = parameters['shuffle']\n",
    "    random_state = None\n",
    "    if 'random_state' in parameters:\n",
    "            random_state = parameters['random_state']\n",
    "    tol = 1e-4\n",
    "    if 'tol' in parameters:\n",
    "            tol = parameters['tol']\n",
    "    verbose = False\n",
    "    if 'verbose' in parameters:\n",
    "            verbose = parameters['verbose']\n",
    "    warm_start = False\n",
    "    if 'warm_start' in parameters:\n",
    "            warm_start = parameters['warm_start']\n",
    "    momentum = 0.9\n",
    "    if 'momentum' in parameters:\n",
    "            momentum = parameters['momentum']\n",
    "    nesterovs_momentum = True\n",
    "    if 'nesterovs_momentum' in parameters:\n",
    "            nesterovs_momentum = parameters['nesterovs_momentum']\n",
    "    early_stopping = False\n",
    "    if 'early_stopping' in parameters:\n",
    "            early_stopping = parameters['early_stopping']\n",
    "    validation_fraction = 0.1\n",
    "    if 'validation_fraction' in parameters:\n",
    "            validation_fraction = parameters['validation_fraction']\n",
    "    beta_1 = 0.9\n",
    "    if 'beta_1' in parameters:\n",
    "            beta_1 = parameters['beta_1']\n",
    "    beta_2 = 0.999\n",
    "    if 'beta_2' in parameters:\n",
    "            beta_2 = parameters['beta_2']\n",
    "    epsilon = 1e-8\n",
    "    if 'epsilon' in parameters:\n",
    "            epsilon = parameters['epsilon']\n",
    "    n_iter_no_change = 10\n",
    "    if 'n_iter_no_change' in parameters:\n",
    "            n_iter_no_change = parameters['n_iter_no_change']\n",
    "    max_fun = 15000\n",
    "    if 'max_fun' in parameters:\n",
    "            max_fun = parameters['max_fun']\n",
    "            \n",
    "    return MLPClassifier(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation=activation,\n",
    "        solver=solver,\n",
    "        alpha=alpha,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        power_t=power_t,\n",
    "        max_iter=max_iter,\n",
    "        shuffle=shuffle,\n",
    "        random_state=random_state,\n",
    "        tol=tol,\n",
    "        verbose=verbose,\n",
    "        warm_start=warm_start,\n",
    "        momentum=momentum,\n",
    "        nesterovs_momentum=nesterovs_momentum,\n",
    "        early_stopping=early_stopping,\n",
    "        validation_fraction=validation_fraction,\n",
    "        beta_1=beta_1,\n",
    "        beta_2=beta_2,\n",
    "        epsilon=epsilon,\n",
    "        n_iter_no_change=n_iter_no_change,\n",
    "        max_fun=max_fun\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(name, parameters):\n",
    "    if name == 'DecisionTree':\n",
    "        return create_dt(parameters)\n",
    "    elif name == 'SVC':\n",
    "        return create_svc(parameters)\n",
    "    elif name == 'GaussianProcess':\n",
    "        return create_gp(parameters)\n",
    "    elif name == 'MLP':\n",
    "        return create_mlp(parameters)\n",
    "    else:\n",
    "        raise UnknownClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Fold and Confusion matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cm_1_fold(classifier, dataset, features, labels):\n",
    "    true_positive, true_negative, false_positive, false_negative = 0, 0, 0, 0\n",
    "    for i in range(len(dataset)):\n",
    "        # Create array [0..N] excluding value i\n",
    "        if i == 0:\n",
    "            indexes = np.array(range(1,N))\n",
    "        elif i < len(dataset) - 1:\n",
    "            indexes = np.append(np.array(range(0,i)), np.array(range(i + 1,N)))\n",
    "        else:\n",
    "            indexes = np.array(range(0,N - 1))\n",
    "        # Train the classifier with indexes values\n",
    "        model = classifier.fit(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        dataset, \n",
    "        class_attribute, \n",
    "        test_set_ratio, \n",
    "        positive_values,\n",
    "        target_metrics,\n",
    "        select_threshold,\n",
    "        max_number,\n",
    "        classifier_list\n",
    "    ):\n",
    "    ds_train, ds_test = split_dataset(len(dataset), test_set_ratio)\n",
    "    # Extract from the dataset col_names, and build FEATURES and LABELS\n",
    "    \n",
    "    \n",
    "    classifiers = []\n",
    "    for classifier_spec in classifier_list:\n",
    "        classifiers.append(create_classifier(classifier_spec[0], classifier_spec[1]))\n",
    "    \n",
    "    confusion_matrixes = []\n",
    "    for classifier in classifiers:\n",
    "        confusion_matrixes.append(create_cm_1_fold(classifier, ds_train))\n",
    "    \n",
    "    return confusion_matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(instance, classifiers):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = train(\n",
    "    range(0,100), \n",
    "    None, \n",
    "    0.3, \n",
    "    None, \n",
    "    None, \n",
    "    None, \n",
    "    None, \n",
    "    [\n",
    "        ['DecisionTree', {'max_depth': 5, 'criterion': 'entropy'}],\n",
    "        ['DecisionTree', {'min_samples_split': 25, 'max_features': 10, 'criterion': 'gini'}],\n",
    "        ['SVC', {'kernel': 'rbf', 'degree': 9}],\n",
    "        ['GaussianProcess', {}],\n",
    "        ['MLP', {}]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                        max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                        random_state=None, splitter='best'),\n",
       " DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                        max_depth=None, max_features=10, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=25,\n",
       "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                        random_state=None, splitter='best'),\n",
       " SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=9, gamma='scale', kernel='rbf',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False),\n",
       " GaussianProcessClassifier(copy_X_train=True, kernel=None, max_iter_predict=100,\n",
       "                           multi_class='one_vs_rest', n_jobs=None,\n",
       "                           n_restarts_optimizer=0, optimizer='fmin_l_bfgs_b',\n",
       "                           random_state=None, warm_start=False),\n",
       " MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "               beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "               hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "               learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "               momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "               power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "               tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "               warm_start=False)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
