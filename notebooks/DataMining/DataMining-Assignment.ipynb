{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data mining assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import collections\n",
    "import random\n",
    "# Visualization\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnknownClassifier(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__('Unknown classifier name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnknownMetric(Exception):\n",
    "    def __init__(self):\n",
    "        super().__init__('Unknown metric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(N, ratio):\n",
    "    indexes = [i for i in range(N)]\n",
    "    limit = int(N * ratio)\n",
    "    # 3N scambi casuali\n",
    "    for i in range(3*N):\n",
    "        a = random.randrange(N)\n",
    "        b = random.randrange(N)\n",
    "        indexes[a], indexes[b] = indexes[b], indexes[a]\n",
    "    return indexes[limit:], indexes[:limit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers creation\n",
    "\n",
    "The classifiers that we will consider are:\n",
    "- Decision Tree ([link](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html))\n",
    "- SVC ([link](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "- Gaussian process classifier ([link](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessClassifier.html))\n",
    "- MLP ([link](earn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html))\n",
    "\n",
    "Which have been taken from this [list](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dt(parameters):\n",
    "    criterion = 'gini'\n",
    "    if 'criterion' in parameters:\n",
    "        criterion = parameters['criterion']\n",
    "    splitter = 'best'\n",
    "    if 'splitter' in parameters:\n",
    "        splitter = parameters['splitter']\n",
    "    max_depth = None\n",
    "    if 'max_depth' in parameters:\n",
    "            max_depth = parameters['max_depth']\n",
    "    min_samples_split = 2\n",
    "    if 'min_samples_split' in parameters:\n",
    "            min_samples_split = parameters['min_samples_split']\n",
    "    min_samples_leaf = 1\n",
    "    if 'min_samples_leaf' in parameters:\n",
    "            min_samples_leaf = parameters['min_samples_leaf']\n",
    "    min_weight_fraction_leaf = 0.0\n",
    "    if 'min_weight_fraction_leaf' in parameters:\n",
    "            min_weight_fraction_leaf = parameters['min_weight_fraction_leaf']\n",
    "    max_features = None\n",
    "    if 'max_features' in parameters:\n",
    "            max_features = parameters['max_features']\n",
    "    random_state = None\n",
    "    if 'random_state' in parameters:\n",
    "            random_state = parameters['random_state']\n",
    "    max_leaf_nodes = None\n",
    "    if 'max_leaf_nodes' in parameters:\n",
    "            max_leaf_nodes = parameters['max_leaf_nodes']\n",
    "    min_impurity_decrease = 0.0\n",
    "    if 'min_impurity_decrease' in parameters:\n",
    "            min_impurity_decrease = parameters['min_impurity_decrease']\n",
    "    class_weight = None\n",
    "    if 'class_weight' in parameters:\n",
    "            class_weight = parameters['class_weight']\n",
    "    ccp_alpha = 0.0\n",
    "    if 'ccp_alpha' in parameters:\n",
    "            ccp_alpha = parameters['ccp_alpha']\n",
    "\n",
    "    return DecisionTreeClassifier(\n",
    "        criterion=criterion,\n",
    "        splitter=splitter,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=random_state,\n",
    "        max_leaf_nodes=max_leaf_nodes,\n",
    "        min_impurity_decrease=min_impurity_decrease,\n",
    "        class_weight=class_weight,\n",
    "        ccp_alpha=ccp_alpha,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_svc(parameters):\n",
    "    C = 1.0\n",
    "    if 'C' in parameters:\n",
    "        C = parameters['C']\n",
    "    kernel = 'rbf'\n",
    "    if 'kernel' in parameters:\n",
    "        kernel = parameters['kernel']\n",
    "    degree = 3\n",
    "    if 'degree' in parameters:\n",
    "        degree = parameters['degree']\n",
    "    gamma = 'scale'\n",
    "    if 'gamma' in parameters:\n",
    "        gamma = parameters['gamma']\n",
    "    coef0 = 0.0\n",
    "    if 'coef0' in parameters:\n",
    "        coef0 = parameters['coef0']\n",
    "    shrinking = True\n",
    "    if 'shrinking' in parameters:\n",
    "        shrinking = parameters['shrinking']\n",
    "    probability = False\n",
    "    if 'probability' in parameters:\n",
    "        probability = parameters['probability']\n",
    "    tol = 1e-3\n",
    "    if 'tol' in parameters:\n",
    "        tol = parameters['tol']\n",
    "    cache_size = 200\n",
    "    if 'cache_size' in parameters:\n",
    "        cache_size = parameters['cache_size']\n",
    "    class_weight = None\n",
    "    if 'class_weight' in parameters:\n",
    "        class_weight = parameters['class_weight']\n",
    "    verbose = False\n",
    "    if 'verbose' in parameters:\n",
    "        verbose = parameters['verbose']\n",
    "    max_iter = -1\n",
    "    if 'max_iter' in parameters:\n",
    "        max_iter = parameters['max_iter']\n",
    "    decision_function_shape = 'ovr'\n",
    "    if 'decision_function_shape' in parameters:\n",
    "        decision_function_shape = parameters['decision_function_shape']\n",
    "    break_ties = False\n",
    "    if 'break_ties' in parameters:\n",
    "        break_ties = parameters['break_ties']\n",
    "    random_state = None\n",
    "    if 'random_state' in parameters:\n",
    "        random_state = parameters['random_state']\n",
    "\n",
    "    return SVC(\n",
    "        C=C,\n",
    "        kernel=kernel,\n",
    "        degree=degree,\n",
    "        gamma=gamma,\n",
    "        coef0=coef0,\n",
    "        shrinking=shrinking,\n",
    "        probability=probability,\n",
    "        tol=tol, cache_size=cache_size,\n",
    "        class_weight=class_weight,\n",
    "        verbose=verbose,\n",
    "        max_iter=max_iter,\n",
    "        decision_function_shape=decision_function_shape,\n",
    "        break_ties=break_ties,\n",
    "        random_state=random_state\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gp(parameters):\n",
    "    kernel = None\n",
    "    if 'kernel' in parameters:\n",
    "            kernel = parameters['kernel']\n",
    "    optimizer = 'fmin_l_bfgs_b'\n",
    "    if 'optimizer' in parameters:\n",
    "            optimizer = parameters['optimizer']\n",
    "    n_restarts_optimizer = 0\n",
    "    if 'n_restarts_optimizer' in parameters:\n",
    "            n_restarts_optimizer = parameters['n_restarts_optimizer']\n",
    "    max_iter_predict = 100\n",
    "    if 'max_iter_predict' in parameters:\n",
    "            max_iter_predict = parameters['max_iter_predict']\n",
    "    warm_start = False\n",
    "    if 'warm_start' in parameters:\n",
    "            warm_start = parameters['warm_start']\n",
    "    copy_X_train = True\n",
    "    if 'copy_X_train' in parameters:\n",
    "            copy_X_train = parameters['copy_X_train']\n",
    "    random_state = None\n",
    "    if 'random_state' in parameters:\n",
    "            random_state = parameters['random_state']\n",
    "    multi_class = 'one_vs_rest'\n",
    "    if 'multi_class' in parameters:\n",
    "            multi_class = parameters['multi_class']\n",
    "    n_jobs = None\n",
    "    if 'n_jobs' in parameters:\n",
    "            n_jobs = parameters['n_jobs']\n",
    "\n",
    "    return GaussianProcessClassifier(\n",
    "        kernel=kernel,\n",
    "        optimizer=optimizer,\n",
    "        n_restarts_optimizer=n_restarts_optimizer,\n",
    "        max_iter_predict=max_iter_predict,\n",
    "        warm_start=warm_start,\n",
    "        copy_X_train=copy_X_train,\n",
    "        random_state=random_state,\n",
    "        multi_class=multi_class,\n",
    "        n_jobs=n_jobs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(parameters):\n",
    "    hidden_layer_sizes = (100,)\n",
    "    if 'hidden_layer_sizes' in parameters:\n",
    "            hidden_layer_sizes = parameters['hidden_layer_sizes']\n",
    "    activation = 'relu'\n",
    "    if 'activation' in parameters:\n",
    "            activation = parameters['activation']\n",
    "    solver = 'adam'\n",
    "    if 'solver' in parameters:\n",
    "            solver = parameters['solver']\n",
    "    alpha = 0.0001\n",
    "    if 'alpha' in parameters:\n",
    "            alpha = parameters['alpha']\n",
    "    batch_size = 'auto'\n",
    "    if 'batch_size' in parameters:\n",
    "            batch_size = parameters['batch_size']\n",
    "    learning_rate = 'constant'\n",
    "    if 'learning_rate' in parameters:\n",
    "            learning_rate = parameters['learning_rate']\n",
    "    learning_rate_init = 0.001\n",
    "    if 'learning_rate_init' in parameters:\n",
    "            learning_rate_init = parameters['learning_rate_init']\n",
    "    power_t = 0.5\n",
    "    if 'power_t' in parameters:\n",
    "            power_t = parameters['power_t']\n",
    "    max_iter = 200\n",
    "    if 'max_iter' in parameters:\n",
    "            max_iter = parameters['max_iter']\n",
    "    shuffle = True\n",
    "    if 'shuffle' in parameters:\n",
    "            shuffle = parameters['shuffle']\n",
    "    random_state = None\n",
    "    if 'random_state' in parameters:\n",
    "            random_state = parameters['random_state']\n",
    "    tol = 1e-4\n",
    "    if 'tol' in parameters:\n",
    "            tol = parameters['tol']\n",
    "    verbose = False\n",
    "    if 'verbose' in parameters:\n",
    "            verbose = parameters['verbose']\n",
    "    warm_start = False\n",
    "    if 'warm_start' in parameters:\n",
    "            warm_start = parameters['warm_start']\n",
    "    momentum = 0.9\n",
    "    if 'momentum' in parameters:\n",
    "            momentum = parameters['momentum']\n",
    "    nesterovs_momentum = True\n",
    "    if 'nesterovs_momentum' in parameters:\n",
    "            nesterovs_momentum = parameters['nesterovs_momentum']\n",
    "    early_stopping = False\n",
    "    if 'early_stopping' in parameters:\n",
    "            early_stopping = parameters['early_stopping']\n",
    "    validation_fraction = 0.1\n",
    "    if 'validation_fraction' in parameters:\n",
    "            validation_fraction = parameters['validation_fraction']\n",
    "    beta_1 = 0.9\n",
    "    if 'beta_1' in parameters:\n",
    "            beta_1 = parameters['beta_1']\n",
    "    beta_2 = 0.999\n",
    "    if 'beta_2' in parameters:\n",
    "            beta_2 = parameters['beta_2']\n",
    "    epsilon = 1e-8\n",
    "    if 'epsilon' in parameters:\n",
    "            epsilon = parameters['epsilon']\n",
    "    n_iter_no_change = 10\n",
    "    if 'n_iter_no_change' in parameters:\n",
    "            n_iter_no_change = parameters['n_iter_no_change']\n",
    "    max_fun = 15000\n",
    "    if 'max_fun' in parameters:\n",
    "            max_fun = parameters['max_fun']\n",
    "            \n",
    "    return MLPClassifier(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation=activation,\n",
    "        solver=solver,\n",
    "        alpha=alpha,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        power_t=power_t,\n",
    "        max_iter=max_iter,\n",
    "        shuffle=shuffle,\n",
    "        random_state=random_state,\n",
    "        tol=tol,\n",
    "        verbose=verbose,\n",
    "        warm_start=warm_start,\n",
    "        momentum=momentum,\n",
    "        nesterovs_momentum=nesterovs_momentum,\n",
    "        early_stopping=early_stopping,\n",
    "        validation_fraction=validation_fraction,\n",
    "        beta_1=beta_1,\n",
    "        beta_2=beta_2,\n",
    "        epsilon=epsilon,\n",
    "        n_iter_no_change=n_iter_no_change,\n",
    "        max_fun=max_fun\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(name, parameters):\n",
    "    if name == 'DecisionTree':\n",
    "        return create_dt(parameters)\n",
    "    elif name == 'SVC':\n",
    "        return create_svc(parameters)\n",
    "    elif name == 'GaussianProcess':\n",
    "        return create_gp(parameters)\n",
    "    elif name == 'MLP':\n",
    "        return create_mlp(parameters)\n",
    "    else:\n",
    "        raise UnknownClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Fold and Confusion matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cm_1_fold(classifier, FEATURES, LABELS):\n",
    "    assert(len(FEATURES) == len(LABELS))\n",
    "    N = len(FEATURES)\n",
    "    true_positive, true_negative, false_positive, false_negative = 0, 0, 0, 0\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        if (i % 1000 == 0):\n",
    "            print('Sample', i)\n",
    "        # Create array [0..N] excluding value i\n",
    "        if i == 0:\n",
    "            indexes = np.array(range(1,N))\n",
    "        elif i < N - 1:\n",
    "            indexes = np.append(np.array(range(0,i)), np.array(range(i + 1,N)))\n",
    "        else:\n",
    "            indexes = np.array(range(0,N - 1))\n",
    "            \n",
    "        # Train the classifier with indexes values\n",
    "        model = classifier.fit(FEATURES[indexes], LABELS[indexes])\n",
    "        \n",
    "        # Predict and check if true/false positive/negative\n",
    "        prediction = model.predict([FEATURES[i]])[0]\n",
    "        predictions.append(prediction)\n",
    "        if prediction == 0:\n",
    "            if prediction == LABELS[i]:\n",
    "                true_negative += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "        else:\n",
    "            if prediction == LABELS[i]:\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                false_positive += 1\n",
    "    \n",
    "    # Calculates confusion matrix\n",
    "    cm = confusion_matrix(LABELS, predictions, normalize='true')\n",
    "    print(cm)\n",
    "    print(confusion_matrix(LABELS, predictions))\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(cm):\n",
    "    return (cm[0][0] + cm[1][1])/sum(sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(metric, cm):\n",
    "    if metric == 'Accuracy':\n",
    "        return calculate_accuracy(cm)\n",
    "    raise UnknownMetric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        dataset, \n",
    "        class_attribute, \n",
    "        test_set_ratio, \n",
    "        positive_values,\n",
    "        target_metrics,\n",
    "        select_threshold,\n",
    "        max_number,\n",
    "        classifier_list\n",
    "    ):\n",
    "    # Extract feature names\n",
    "    ds_train, ds_test = split_dataset(len(dataset), test_set_ratio)\n",
    "    feature_names = []\n",
    "    for col_name in dataset.columns:\n",
    "        if col_name != class_attribute:\n",
    "            feature_names.append(col_name)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    oh_encoder = preprocessing.OneHotEncoder().fit(dataset[feature_names])\n",
    "    FEATURES = oh_encoder.transform(dataset[feature_names]).toarray()\n",
    "    LABELS = np.array([1 if x in positive_values else 0 for x in dataset[class_attribute]])\n",
    "    \n",
    "    # Creation of the classifiers\n",
    "    classifiers = []\n",
    "    for classifier_spec in classifier_list:\n",
    "        classifiers.append(create_classifier(classifier_spec[0], classifier_spec[1]))\n",
    "    \n",
    "    # Computation of the confusion matrixes with 1-fold\n",
    "    confusion_matrixes = []\n",
    "    for classifier in classifiers:\n",
    "        print('Classifier:', classifiers.index(classifier))\n",
    "        confusion_matrixes.append(create_cm_1_fold(classifier, FEATURES[ds_train], LABELS[ds_train]))\n",
    "    \n",
    "    # Calculate score for each classifier, taking those whith a value > select_threshold\n",
    "    classifier_scores = []\n",
    "    for i in range(len(classifiers)):\n",
    "        cm = confusion_matrixes[i]\n",
    "        score = calculate_score(target_metrics, cm)\n",
    "        if score > select_threshold:\n",
    "            classifier_scores.append({\n",
    "                'index': i,\n",
    "                'score': score\n",
    "            })\n",
    "    \n",
    "    # Sort them by score\n",
    "    classifier_scores = sorted(classifier_scores, \n",
    "                               key=lambda x: x['score'],\n",
    "                               reverse=True)\n",
    "    print(classifier_scores)\n",
    "    \n",
    "    # Take the desired ones\n",
    "    if max_number == 0:\n",
    "        selected_classifiers = [x['index'] for x in classifier_scores]\n",
    "    else:\n",
    "        selected_classifiers = [x['index'] for x in classifier_scores[:max_number]]\n",
    "    # Note: selected classifier is a list with the indexes of the selected classifiers\n",
    "    \n",
    "    return selected_classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(instance, classifiers):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nursery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nursery_header = [\n",
    "    'parents',\n",
    "    'has_nurs',\n",
    "    'form',\n",
    "    'children',\n",
    "    'housing',\n",
    "    'finance',\n",
    "    'social',\n",
    "    'health',\n",
    "    'classification'\n",
    "]\n",
    "ds_nursery = pd.read_csv(\"/datasets/Nursery/nursery.csv\", names=nursery_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: 0\n",
      "Sample 0\n",
      "Sample 1000\n",
      "Sample 2000\n",
      "Sample 3000\n",
      "Sample 4000\n",
      "Sample 5000\n",
      "Sample 6000\n",
      "Sample 7000\n",
      "Sample 8000\n",
      "Sample 9000\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "[[6019    0]\n",
      " [   0 3053]]\n",
      "Classifier: 1\n",
      "Sample 0\n",
      "Sample 1000\n",
      "Sample 2000\n",
      "Sample 3000\n",
      "Sample 4000\n",
      "Sample 5000\n",
      "Sample 6000\n",
      "Sample 7000\n",
      "Sample 8000\n",
      "Sample 9000\n",
      "[[1.00000000e+00 0.00000000e+00]\n",
      " [3.27546675e-04 9.99672453e-01]]\n",
      "[[6019    0]\n",
      " [   1 3052]]\n",
      "[{'index': 0, 'score': 1.0}, {'index': 1, 'score': 0.9998362266622993}]\n"
     ]
    }
   ],
   "source": [
    "classifiers = train(\n",
    "    ds_nursery, \n",
    "    'classification', \n",
    "    0.3, \n",
    "    ['not_recom'],  # ['spec_prior'], \n",
    "    'Accuracy', \n",
    "    0.6, \n",
    "    3, \n",
    "    [\n",
    "        ['DecisionTree', {'max_depth': 5, 'criterion': 'entropy'}],\n",
    "        ['DecisionTree', {'min_samples_split': 25, 'max_features': 10, 'criterion': 'gini'}],\n",
    "        # ['SVC', {'kernel': 'rbf', 'degree': 9}],\n",
    "        # ['GaussianProcess', {}],\n",
    "        # ['MLP', {}]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 2, 'score': 0.8},\n",
       " {'index': 1, 'score': 0.5},\n",
       " {'index': 4, 'score': 0.3},\n",
       " {'index': 3, 'score': 0.2}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =[\n",
    "    {'index': 1, 'score': 0.5},\n",
    "    {'index': 2, 'score': 0.8},\n",
    "    {'index': 3, 'score': 0.2},\n",
    "    {'index': 4, 'score': 0.3}\n",
    "]\n",
    "\n",
    "sorted(a, key=lambda x : x['score'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4][:8]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
